{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1a73ec-57b8-44ff-9195-d97e76c77edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\victus\\biswashreya\\speech-completition-prediction\\.venv\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#'\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama\n",
    "!pip install tqdm ipywidgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c1205",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ../clustering/intermediate_data/clustered_embeddings.csv\n",
      "Loaded 3474 rows after cleaning and timestamp conversion.\n",
      "Grouped into 368 unique file-cluster segments.\n",
      "\n",
      "Starting title generation with Ollama model: phi3:mini\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c38cb6b702f45d28864e26a528a877a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Titles:   0%|          | 0/368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving titles to titles_phi3_mini.json\n",
      "\n",
      "Process completed! Titles saved to titles_phi3_mini.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.notebook import tqdm \n",
    "import ollama \n",
    "import re \n",
    "\n",
    "\n",
    "def convert_timestamp_to_seconds(timestamp_str):\n",
    "    if pd.isna(timestamp_str): \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    timestamp_str = str(timestamp_str).strip()\n",
    "\n",
    "    \n",
    "    parts = list(map(int, timestamp_str.split(':')))\n",
    "\n",
    "    if len(parts) == 2: \n",
    "        minutes, seconds = parts\n",
    "        return float(minutes * 60 + seconds)\n",
    "    elif len(parts) == 3: \n",
    "        hours, minutes, seconds = parts\n",
    "        return float(hours * 3600 + minutes * 60 + seconds)\n",
    "    else:\n",
    "        \n",
    "        print(f\"Warning: Unexpected timestamp format '{timestamp_str}'. Returning None.\")\n",
    "        return None\n",
    "\n",
    "CSV_PATH = \"../clustering/intermediate_data/clustered_embeddings.csv\"\n",
    "OUTPUT_JSON = \"titles_phi3_mini.json\"\n",
    "OLLAMA_MODEL_NAME = \"phi3:mini\"\n",
    "\n",
    "print(f\"Loading data from: {CSV_PATH}\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "\n",
    "df['start'] = df['start'].apply(convert_timestamp_to_seconds)\n",
    "df['end'] = df['end'].apply(convert_timestamp_to_seconds)\n",
    "\n",
    "df = df[df[\"text\"].notnull() & df[\"cluster\"].notnull() & df[\"start\"].notnull() & df[\"end\"].notnull()]\n",
    "print(f\"Loaded {len(df)} rows after cleaning and timestamp conversion.\")\n",
    "\n",
    "grouped = df.groupby([\"file\", \"cluster\"]).agg({\n",
    "    \"start\": \"min\", \n",
    "    \"end\": \"max\",\n",
    "    \"text\": lambda x: \" \".join(x)\n",
    "}).reset_index()\n",
    "print(f\"Grouped into {len(grouped)} unique file-cluster segments.\")\n",
    "\n",
    "\n",
    "max_length = 256 \n",
    "\n",
    "output = {}\n",
    "\n",
    "print(f\"\\nStarting title generation with Ollama model: {OLLAMA_MODEL_NAME}\")\n",
    "for i, row in tqdm(grouped.iterrows(), total=len(grouped), desc=\"Generating Titles\"):\n",
    "    file = row[\"file\"]\n",
    "    cluster = str(row[\"cluster\"])\n",
    "    \n",
    "    start = row[\"start\"]\n",
    "    end = row[\"end\"]\n",
    "    combined_text = row[\"text\"][:5000] \n",
    "\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant. Please generate a short, human-friendly title for the following transcript segment of an educational lecture.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Transcript:\\n\\\"\\\"\\\"{combined_text}\\\"\\\"\\\"\\n\\nTitle:\"}\n",
    "    ]\n",
    "\n",
    "    title = \"\" \n",
    "\n",
    "    try:\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model=OLLAMA_MODEL_NAME,\n",
    "            messages=messages,\n",
    "            options={\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.9,\n",
    "                \"num_predict\": max_length\n",
    "            }\n",
    "        )\n",
    "\n",
    "        \n",
    "        if response and 'message' in response and 'content' in response['message']:\n",
    "            generated_content = response['message']['content']\n",
    "            title_parts = generated_content.split(\"Title:\")\n",
    "            if len(title_parts) > 1:\n",
    "                title = title_parts[-1].strip().replace(\"\\n\", \" \")\n",
    "            else:\n",
    "                title = generated_content.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "            if title.startswith('\"') and title.endswith('\"'):\n",
    "                title = title[1:-1]\n",
    "            if title.startswith(\"'\") and title.endswith(\"'\"):\n",
    "                title = title[1:-1]\n",
    "        else:\n",
    "            title = \"Error: Could not parse Ollama response\"\n",
    "            print(f\"\\nWarning: Unexpected Ollama response structure for file {file}, cluster {cluster}. Response: {response}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        title = f\"Error: {type(e).__name__} - {e}\"\n",
    "        print(f\"\\nError generating title for file {file}, cluster {cluster}: {e}\")\n",
    "\n",
    "    if file not in output:\n",
    "        output[file] = {}\n",
    "\n",
    "    output[file][f\"cluster{cluster}\"] = {\n",
    "        \"title\": title,\n",
    "        \"start\": start,\n",
    "        \"end\": end\n",
    "    }\n",
    "\n",
    "\n",
    "print(f\"\\nSaving titles to {OUTPUT_JSON}\")\n",
    "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nProcess completed! Titles saved to {OUTPUT_JSON}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e24c55-0314-4c37-8b8b-fb1229a1e13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(speechenv)",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
