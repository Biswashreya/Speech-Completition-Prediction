import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import spacy

df = pd.read_csv("../clustering/intermediate_data/clustered_embeddings.csv")
df = df[df["text"].notnull() & df["cluster"].notnull()]

grouped = df.groupby("cluster")["text"].apply(lambda x: " ".join(x)).reset_index()
grouped.columns = ["cluster", "combined_text"]

nlp = spacy.load("en_core_web_sm")

def textrank_keywords(text, top_n=5):
    doc = nlp(text)
    candidates = [chunk.text for chunk in doc.noun_chunks]
    vectorizer = TfidfVectorizer(stop_words='english')
    X = vectorizer.fit_transform(candidates)
    scores = X.sum(axis=0).A1
    keywords = [vectorizer.get_feature_names_out()[i] for i in scores.argsort()[::-1][:top_n]]
    return keywords

for i, row in grouped.iterrows():
    print(f"\nCluster {row['cluster']}")
    print("TextRank:", textrank_keywords(row["combined_text"]))
